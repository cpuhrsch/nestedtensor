{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nestedtensor\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def print_eval(s):\n",
    "    colorS = \"<span style='color:darkred'>$ {}</span>\".format(s)\n",
    "    display(Markdown('**{}**'.format(colorS))) \n",
    "    print('{}\\n'.format(str(eval(s))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom nn.functionals\n",
    "\n",
    "By default all nn.functionals are implemented as a tensorwise function. However, in some cases we want to support custom semantics that come about by slight modifications to the lifted function. Take nn.functional.conv2d as an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style='color:darkred'>$ nt.size()</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, None, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nt = nestedtensor.nested_tensor([\n",
    "    torch.rand(3, 10, 30),\n",
    "    torch.rand(3, 20, 40),\n",
    "    torch.rand(3, 30, 50)\n",
    "])\n",
    "nt1 = nestedtensor.nested_tensor([\n",
    "    torch.rand(1, 3, 10, 30),\n",
    "    torch.rand(1, 3, 20, 40),\n",
    "    torch.rand(1, 3, 30, 50)\n",
    "])\n",
    "weight = torch.rand(64, 3, 7, 7)\n",
    "print_eval(\"nt.size()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default this function fails, because the components do not have a batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, NestedTensors implement a version of conv2d that doesn't require a batch dimension for ease of use and for efficiency (more on that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style='color:darkred'>$ torch.nn.functional.conv2d(nt, weight).size()</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 64, None, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval(\"torch.nn.functional.conv2d(nt, weight).size()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a similar story for nn.functional.embedding_bag. The lifted version only works on elements of batch size 1, unless given an offset, which is an unnecessary annoyance. We extend the lifted embedding_bag to support inputs of dimension 1, if offset is set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "NestedTensor.to is currently not implemented.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5fda6caf4208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m nt2 = (nestedtensor.nested_tensor([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ]) * 10).to(torch.int64)\n",
      "\u001b[0;32m/scratch/cpuhrsch/repos/nestedtensor/nestedtensor/nested/nested.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         raise NotImplementedError(\n\u001b[0m\u001b[1;32m    266\u001b[0m             \"NestedTensor.to is currently not implemented.\")\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnestedtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_nested_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: NestedTensor.to is currently not implemented."
     ]
    }
   ],
   "source": [
    "nt2 = (nestedtensor.nested_tensor([\n",
    "    torch.rand(1, 30),\n",
    "    torch.rand(1, 40),\n",
    "    torch.rand(1, 50)\n",
    "]) * 10).to(torch.int64)\n",
    "nt3 = (nestedtensor.nested_tensor([\n",
    "    torch.rand(30),\n",
    "    torch.rand(40),\n",
    "    torch.rand(50)\n",
    "]) * 10).to(torch.int64)\n",
    "nt4 = (nestedtensor.nested_tensor([\n",
    "    [\n",
    "        torch.rand(1, 30),\n",
    "    ],\n",
    "    [\n",
    "        torch.rand(1, 40),\n",
    "        torch.rand(1, 50)\n",
    "    ]\n",
    "]) * 10).to(torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS TEMPORARILY DISABLED\n",
    "# weight = torch.rand(100, 256)\n",
    "# print_eval(\"torch.nn.functional.embedding_bag(nt2, weight).nested_size()\")\n",
    "# print_eval(\"torch.nn.functional.embedding_bag(nt3, weight).nested_size()\")\n",
    "# print_eval(\"torch.nn.functional.embedding_bag(nt4, weight).nested_size()\")\n",
    "# print_eval(\"torch.nn.EmbeddingBag(100, 256)(nt2).nested_size()\")\n",
    "# print_eval(\"torch.nn.EmbeddingBag(100, 256)(nt3).nested_size()\")\n",
    "# print_eval(\"torch.nn.EmbeddingBag(100, 256)(nt4).nested_size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt3 = nt3.float()\n",
    "print_eval(\"nt3\")\n",
    "print_eval(\"nt3.size()\")\n",
    "print_eval(\"nt3.nested_size()\")\n",
    "print_eval(\"nestedtensor.nested_tensor(nt3.nested_size(1))\")\n",
    "nt4 = nt3 / nestedtensor.nested_tensor(nt3.nested_size(1))\n",
    "print_eval(\"nt4\")\n",
    "print_eval(\"nt4.size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt5 = nestedtensor.nested_tensor([\n",
    "    torch.rand(30, 10),\n",
    "    torch.rand(40, 10),\n",
    "    torch.rand(50, 10)\n",
    "])\n",
    "print_eval(\"nt5.nested_size()\")\n",
    "print_eval(\"torch.mm(nt5, torch.rand(10, 5)).nested_size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(\"nt5.argmax(1)\")\n",
    "print_eval(\"nt5.argmax(1).size()\")\n",
    "print_eval(\"nt5.argmax(1).to_tensor()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS TEMOPORARILY DISABLED\n",
    "# print_eval(\"nt5.nested_size()\")\n",
    "# print_eval(\"nt5.argmax(2).nested_size()\")\n",
    "# print_eval(\"torch.nn.functional.cross_entropy(nt5, nt5.argmax(2))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt6 = nestedtensor.nested_tensor([torch.rand(10, 10), torch.rand(20, 20), torch.rand(30, 30)])\n",
    "print_eval(\"nt6.lu()[0].size()\")\n",
    "print_eval(\"nt6.lu()[1].size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt7 = nestedtensor.nested_tensor([[torch.rand(1, 10), torch.rand(2, 20)], [torch.rand(3, 30)]])\n",
    "nt8 = nestedtensor.nested_tensor([[torch.rand(10, 1), torch.rand(20, 2)], [torch.rand(30, 3)]])\n",
    "print_eval(\"torch.mm(nt7, nt8)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
