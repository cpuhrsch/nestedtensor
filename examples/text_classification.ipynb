{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import io\n",
    "import tarfile\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import time\n",
    "from collections import Counter\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import nestedtensor\n",
    "from nestedtensor import nested_tensor\n",
    "\n",
    "URL = \"https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Point = namedtuple('Point', 'label text')\n",
    "\n",
    "def get_data(URL):\n",
    "    r = requests.get(URL)\n",
    "    file_like_object = io.BytesIO(r.content)\n",
    "    tar = tarfile.open(fileobj=file_like_object)\n",
    "    d = {}\n",
    "    for member in tar.getmembers():\n",
    "        if member.isfile() and member.name.endswith('csv'):\n",
    "            k = 'train' if 'train' in member.name else 'test'\n",
    "            d[k] = tar.extractfile(member)\n",
    "    return d\n",
    "\n",
    "\n",
    "def preprocess(iterator):\n",
    "    def _preprocess(line):\n",
    "        line = line.decode('UTF-8')\n",
    "        line = line.lower()\n",
    "        line = re.sub(r'[^0-9a-zA-Z,\\s]', \"\", line)\n",
    "        line = line.split(',')\n",
    "        label = int(line[0]) - 1\n",
    "        text = (\" \".join(line[1:])).split()\n",
    "        if len(line) > 2:\n",
    "            return Point(label=label, text=text)\n",
    "    for line in iterator:\n",
    "        yield _preprocess(line)\n",
    "\n",
    "\n",
    "def build_vocab(iterator):\n",
    "    counter = Counter()\n",
    "    labels = set()\n",
    "    for point in iterator:\n",
    "        counter.update(point.text)\n",
    "        labels.add(point.label)\n",
    "    vocab = {}\n",
    "    for i, (word, count) in enumerate(counter.most_common()):\n",
    "        vocab[word] = i\n",
    "\n",
    "    return vocab, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(URL)\n",
    "data = {k: list(preprocess(v)) for (k, v) in data.items()}\n",
    "vocab, labels = build_vocab(data['train'])\n",
    "UNK = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        return self.fc(self.embedding(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 10\n",
    "model = TextSentiment(len(vocab) + 1, embed_dim, len(labels)).cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(data):\n",
    "    data = [torch.tensor(list(map(lambda x: vocab.get(x, UNK), tokens))) for tokens in data]\n",
    "    return data\n",
    "\n",
    "def yield_data_futures(data):\n",
    "    random.shuffle(data)\n",
    "    labels = []\n",
    "    batch_data = []\n",
    "    futures = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=8) as executor:\n",
    "        for i, point in enumerate(data):\n",
    "            # Stop accumulating lines of text once we reach 4000 tokens or more\n",
    "            # This yields variable batch sizes, but with consistent memory pressure\n",
    "            if sum(map(len, batch_data), 0) < 10000:\n",
    "                labels.append(point.label)\n",
    "                batch_data.append(point.text)\n",
    "            else:\n",
    "                if len(futures) < 40:\n",
    "                    futures.append((torch.tensor(labels), executor.submit(create_batch, batch_data)))\n",
    "                else:\n",
    "                    yield futures[0]\n",
    "                    futures = futures[1:]\n",
    "                labels = []\n",
    "                batch_data = []\n",
    "\n",
    "    for future in futures:\n",
    "        yield future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 27205880\n",
      "NestedSize([\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([]),\n",
      "\ttorch.Size([])\n",
      "])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [1, 14], got [1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cd13ade5f64c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cpuhrsch/miniconda3scratch/envs/nightlycuda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cpuhrsch/miniconda3scratch/envs/nightlycuda/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m    954\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cpuhrsch/miniconda3scratch/envs/nightlycuda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2461\u001b[0m         \u001b[0mtens_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2463\u001b[0;31m             return handle_torch_function(\n\u001b[0m\u001b[1;32m   2464\u001b[0m                 \u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m                 \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cpuhrsch/miniconda3scratch/envs/nightlycuda/lib/python3.8/site-packages/torch/overrides.py\u001b[0m in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;31m# Use `public_api` instead of `implementation` so __torch_function__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;31m# implementations can do equality/identity comparisons.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverloaded_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/cpuhrsch/repos/nestedtensor/nestedtensor/nested/nested.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             return _wrap_result(\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mnestedtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimpl_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimpl_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             )\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimpl_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimpl_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [1, 14], got [1]"
     ]
    }
   ],
   "source": [
    "num_tokens = sum(map(lambda x: len(x.text), data['train']))\n",
    "print(\"Total number of tokens: {}\".format(num_tokens))\n",
    "for epoch in range(5):\n",
    "    i = 0\n",
    "    t0 = time.time()\n",
    "    for labels, future in yield_data_futures(data['train']):\n",
    "        batch = future.result()\n",
    "        labels = nested_tensor(labels.unbind(), device=torch.device('cuda'), dtype=torch.int64)\n",
    "        print(labels.nested_size())\n",
    "        batch = nested_tensor(batch, device=torch.device('cuda'), dtype=torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 16 == 1:\n",
    "            sys.stderr.write(\n",
    "                \"\\rtime: {:3.0f}s epoch: {:3.0f} lr: {:3.6f} loss: {:3.6f}\".format(\n",
    "                    time.time() - t0, \n",
    "                    epoch, \n",
    "                    scheduler.get_lr()[0],\n",
    "                    loss, \n",
    "                )\n",
    "            )\n",
    "            sys.stderr.flush()\n",
    "        i += batch.numel()\n",
    "    scheduler.step()\n",
    "    sys.stderr.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [(tb[0], model(tb[1].result().to('cuda')).argmax(1).cpu()) for tb in yield_data_futures(data['test'])]\n",
    "predictions = torch.cat(list(map(lambda x: x[1], output)))\n",
    "labels = torch.cat(list(map(lambda x: x[0], output)))\n",
    "\n",
    "print(\"Test accuracy: {}\".format((labels == predictions).sum().float() / len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
