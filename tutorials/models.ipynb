{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nestedtensor\n",
    "from IPython.display import Markdown, display\n",
    "def print_eval(s):\n",
    "    colorS = \"<span style='color:darkred'>$ {}</span>\".format(s)\n",
    "    display(Markdown('**{}**'.format(colorS))) \n",
    "    print('{}\\n'.format(str(eval(s))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code implements a basic Text classification (or related) model. Instead of worrying about padding or some offset keyword argument for something like EmbeddingBag the user can simply pass the NestedTensor to the model and let it deal with it. This also opens doors for creating variably sized batches with batch size simply determined by a number of desired tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**<span style='color:darkred'>$ nt_text.nested_size()</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NestedSize([\n",
      "\ttorch.Size([72]),\n",
      "\ttorch.Size([78]),\n",
      "\ttorch.Size([80]),\n",
      "\ttorch.Size([79])\n",
      "])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**<span style='color:darkred'>$ model(nt_text).nested_size()</span>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NestedSize([\n",
      "\ttorch.Size([5]),\n",
      "\ttorch.Size([5]),\n",
      "\ttorch.Size([5]),\n",
      "\ttorch.Size([5])\n",
      "])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_tensors(num_tensor, vocab_size):\n",
    "    sentence_lengths = torch.normal(75.0, 10.0, size=(num_tensor,)).long()\n",
    "    return [(torch.rand(l) * vocab_size).long() for l in sentence_lengths]\n",
    "\n",
    "class TextModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        emb = self.embedding(text)\n",
    "        return self.fc(emb).sum(1).softmax(1)\n",
    "\n",
    "vocab_size = 10000\n",
    "model = TextModel(10000, 256, 5)\n",
    "nt_text = nestedtensor.nested_tensor(generate_tensors(4, 10000), dtype=torch.int64)\n",
    "print_eval(\"nt_text.nested_size()\")\n",
    "print_eval(\"model(nt_text).nested_size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
